{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab_recurrent_2_132326.ipynb","provenance":[{"file_id":"1CmRdV8KkPf9j0DDk_bC8IT6SLPbRM1vG","timestamp":1579513346527},{"file_id":"1QpsxkPhAE-EgfwYsOsRPd_KobYhyFan9","timestamp":1572989882145},{"file_id":"1YyS2vvPmtCATqCXPNrdic-aKZxtdm35j","timestamp":1572989874798},{"file_id":"1aknfFPOfmvYFqJdqkyaHQLjomDNh4KpT","timestamp":1572989868630},{"file_id":"1XAUKPGNFNzkiuiNUTFGzxJh3VxFAWamq","timestamp":1572989860085}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ebvqJaNU9bkH","colab_type":"text"},"source":["# Elementy Inteligencji Obliczeniowej - Sieci Neuronowe\n","\n","\n","---\n","\n","**Prowadzący:** Jakub Bednarek<br>\n","**Kontakt:** jakub.bednarek@put.poznan.pl<br>\n","**Materiały:** [Strona WWW](http://jakub.bednarek.pracownik.put.poznan.pl)\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"i0tVMrm99g5w","colab_type":"text"},"source":["## Uwaga\n","\n","* **Aby wykonać polecenia należy najpierw przejść do trybu 'playground'. File -> Open in Playground Mode**\n","* Nowe funkcje Colab pozwalają na autouzupełnianie oraz czytanie dokumentacji"]},{"cell_type":"markdown","metadata":{"id":"Wlq47LA0BuBB","colab_type":"text"},"source":["## Cel ćwiczeń:\n","- zapoznanie się z rekurencyjnymi sieciami neuronowymi,\n","- stworzenie modelu sieci z warstwami rekurencyjnymi dla zbioru danych MNIST,\n","- stworzenie własnych implementacji warstwami neuronowych"]},{"cell_type":"code","metadata":{"id":"SxLU8paIDmUe","colab_type":"code","outputId":"e2a7d178-91d8-4966-d720-b1a3530e6dac","executionInfo":{"status":"ok","timestamp":1580656854448,"user_tz":-60,"elapsed":2955,"user":{"displayName":"Dominik Szmyt","photoUrl":"","userId":"04255669248458570913"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%tensorflow_version 2.x\n","\n","import tensorflow as tf\n","import numpy as np"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"scL5_bHTD-M7","colab_type":"code","colab":{}},"source":["from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, LSTM, LSTMCell, SimpleRNNCell\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.optimizers import Adadelta, RMSprop\n","from tensorflow.python.keras import backend as K\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wV_u-YBWEJ8X","colab_type":"code","colab":{}},"source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","\n","x_train = x_train.astype('float32')  # shape: 60000, 28, 28\n","x_test = x_test.astype('float32')    # shape: 10000, 28, 28\n","x_train /= 255  # normalizacja wartości do przedziału [0, 1]\n","x_test /= 255\n","\n","y_train = to_categorical(y_train, 10)  # zamiana etykiety na one-hot encoding; np. 2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n","y_test = to_categorical(y_test, 10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ppmDSGoyFuJ9","colab_type":"text"},"source":["## Sieci rekurencyjne\n","http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n","\n","https://www.tensorflow.org/guide/keras/rnn\n","\n","https://www.tensorflow.org/guide/function\n","\n","http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n","\n","http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/\n","\n","Przykładowy model z warstwą rekurencyjną dla danych MNIST:"]},{"cell_type":"code","metadata":{"id":"ViqotGlHGy9t","colab_type":"code","colab":{}},"source":["class RecurrentModel(Model):\n","\n","    def __init__(self, num_classes=10):\n","        super(RecurrentModel, self).__init__(name='my_model')\n","        self.num_classes = num_classes\n","        # Define your layers here.\n","        self.lstm_1 = LSTM(128, activation='relu')\n","        self.dense_1 = Dense(num_classes, activation='softmax')\n","\n","    def call(self, inputs):\n","        # Define your forward pass here,\n","        # using layers you previously defined (in `__init__`).\n","        x = self.lstm_1(inputs)\n","        return self.dense_1(x)\n","\n","model = RecurrentModel(num_classes=10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jFs-QBFtEp0s","colab_type":"code","outputId":"c9a87732-7167-45cd-99ab-36c9da9c4633","executionInfo":{"status":"ok","timestamp":1580656964893,"user_tz":-60,"elapsed":113357,"user":{"displayName":"Dominik Szmyt","photoUrl":"","userId":"04255669248458570913"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["model.compile(optimizer=RMSprop(),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(x_train, y_train, batch_size=32, epochs=2)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Train on 60000 samples\n","Epoch 1/2\n","60000/60000 [==============================] - 55s 920us/sample - loss: 0.5992 - accuracy: 0.8227\n","Epoch 2/2\n","60000/60000 [==============================] - 55s 910us/sample - loss: 0.1541 - accuracy: 0.9587\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fceceedc518>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"ZgtZzVYg1361","colab_type":"text"},"source":["### Zadanie 1\n","Rozszerz model z powyższego przykładu o kolejną warstwę rekurencyjną przed gęstą warstwą wyjściową.\n","\n","Standardowe sieci neuronowe generują jeden wynik na podstawie jednego inputu.\n","Natomiast sieci rekurencyjne przetwarzają dane sekwencyjnie, w każdym kroku łącząc wynik poprzedniego przetwarzania i aktualnego wejścia. Dlatego domyślnym wejściem sieci neuronowej jest tensor 3-wymiarowy ([batch_size,sequence_size,sample_size]).\n","Domyślnie warstwy rekurencyjne w Kerasie zwracają tylko wyniki przetwarzania ostatniego\n","kroku (otrzymują tensor 3-wymiarowy, zwracają tensor 2-wymiarowy). Jeśli chcesz zwrócić sekwencje wyników wszystkich kroków przetwarzania dla warstwy rekurencyjnej, musisz ustawić parametr return_sequences=True.\n"]},{"cell_type":"code","metadata":{"id":"MSJUzxAc15uZ","colab_type":"code","outputId":"bb92045b-b396-4ffd-feac-cda6a2c901ab","executionInfo":{"status":"ok","timestamp":1580657201288,"user_tz":-60,"elapsed":349738,"user":{"displayName":"Dominik Szmyt","photoUrl":"","userId":"04255669248458570913"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["class DoubleRecurrentModel(Model):\n","\n","    def __init__(self, num_classes=10):\n","        super(DoubleRecurrentModel, self).__init__(name='double_recurrent_model')\n","        self.num_classes = num_classes\n","        self.lstm_1 = LSTM(128, activation='relu', return_sequences=True)\n","        self.lstm_2 = LSTM(128, activation='relu')\n","        self.dense_1 = Dense(num_classes, activation='softmax')\n","        \n","\n","    def call(self, inputs):\n","        x = self.lstm_1(inputs)\n","        x = self.lstm_2(x)\n","        return self.dense_1(x)\n","\n","recurrentModel = DoubleRecurrentModel()\n","\n","recurrentModel.compile(optimizer=RMSprop(),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","recurrentModel.fit(x_train, y_train, batch_size=32, epochs=2)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Train on 60000 samples\n","Epoch 1/2\n","60000/60000 [==============================] - 119s 2ms/sample - loss: 0.5585 - accuracy: 0.8294\n","Epoch 2/2\n","60000/60000 [==============================] - 118s 2ms/sample - loss: 0.1322 - accuracy: 0.9643\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fcecb62d978>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"fYDLWjdseB4H","colab_type":"text"},"source":["### Zadanie 2 \n","Wykorzystując model z przykładu, napisz sieć rekurencyjną przy użyciu SimpleRNNCell.\n","\n","Cell implementuje tylko operacje wykonywane przez warstwę\n","rekurencyjną dla jednego kroku. Warstwy rekurencyjne w każdym kroku\n","łączą wynik operacji poprzedniego kroku i aktualny input.\n","Wykorzystaj pętle for do wielokrotnego wywołania komórki SimpleRNNCell (liczba kroków to liczba elementów w sekwencji). Aby wywołać SimpleRNNCell dla pojedynczego wejścia i stanu należy użyć jej metody ```call``` analogicznie jak w przypadku własnych modeli (tzn. ```my_model(input)```). \n","\n","\n","\n","Wywołanie zainicjalizowanej komórki rekurencyjnej wymaga podania aktualnego inputu i listy stanów ukrytych poprzedniego kroku (SimpleRNNCell ma jeden stan).\n","\n","Trzeba zainicjalizować ukryty stan warstwy z wartościami początkowymi (można wykorzystać rozkład normalny - tf.random.normal)."]},{"cell_type":"code","metadata":{"id":"6yZ8yKmbee44","colab_type":"code","outputId":"21cd1d55-88b7-4f1e-e8bd-86ce5624fbc8","executionInfo":{"status":"ok","timestamp":1580657228763,"user_tz":-60,"elapsed":377201,"user":{"displayName":"Dominik Szmyt","photoUrl":"","userId":"04255669248458570913"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["class SimpleRNNCellModel(Model):\n","\n","    def __init__(self, num_classes=10):\n","        super(SimpleRNNCellModel, self).__init__(name='simple_rnn_cell_model')\n","        self.num_classes = num_classes\n","\n","        self.simple_rnn_cell = SimpleRNNCell(128, activation='relu')\n","        self.dense = Dense(self.num_classes, activation='softmax') \n","\n","    def call(self, inputs):\n","        sequence = [tf.random.normal([32,128])]\n","        for i in range(28):\n","            out, sequence = self.simple_rnn_cell(inputs[:,i,:], sequence)\n","        return self.dense(out)\n","\n","simpleRNNCellModel = SimpleRNNCellModel()\n","\n","simpleRNNCellModel.compile(optimizer=RMSprop(),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","simpleRNNCellModel.fit(x_train, y_train, batch_size=32, epochs=2)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Train on 60000 samples\n","Epoch 1/2\n","60000/60000 [==============================] - 14s 231us/sample - loss: 0.4967 - accuracy: 0.8415\n","Epoch 2/2\n","60000/60000 [==============================] - 13s 218us/sample - loss: 0.2231 - accuracy: 0.9362\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fcecb1964e0>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"eyPGkC6oiEd5","colab_type":"text"},"source":["### Zadanie 3\n","Zamień komórkę rekurencyjną z poprzedniego zadania na LSTMCell (LSTMCell ma dwa stany ukryte)."]},{"cell_type":"code","metadata":{"id":"C5MPQ1UcigN5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"f08b67ac-67ef-4313-9e90-772571f8fb99","executionInfo":{"status":"ok","timestamp":1580657323176,"user_tz":-60,"elapsed":471603,"user":{"displayName":"Dominik Szmyt","photoUrl":"","userId":"04255669248458570913"}}},"source":["class LSTMCellModel(Model):\n","\n","    def __init__(self, num_classes=10):\n","        super(LSTMCellModel, self).__init__(name='lstm_cell_model')\n","        self.num_classes = num_classes\n","\n","        self.lstm_cell = LSTMCell(128, activation='relu')\n","        self.dense = Dense(self.num_classes, activation='softmax') \n","\n","    def call(self, inputs):\n","        sequence = [tf.random.normal([32,128]), tf.random.normal([32, 128])]\n","        for i in range(28):\n","            out, sequence = self.lstm_cell(inputs[:,i,:], sequence)\n","        return self.dense(out)\n","\n","lstmCellModel = LSTMCellModel()\n","\n","lstmCellModel.compile(optimizer=RMSprop(),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","lstmCellModel.fit(x_train, y_train, batch_size=32, epochs=2)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Train on 60000 samples\n","Epoch 1/2\n","60000/60000 [==============================] - 48s 799us/sample - loss: 0.6139 - accuracy: 0.8148\n","Epoch 2/2\n","60000/60000 [==============================] - 46s 764us/sample - loss: 0.1371 - accuracy: 0.9602\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fceca583e80>"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"prwjaEv2efs3","colab_type":"text"},"source":["### Zadanie 4\n","Wykorzystując model z poprzedniego zadania, stwórz model sieci\n","neuronowej z własną implementacją prostej warstwy rekurencyjnej.\n","- w call zamień self.lstm_cell_layer(x) na wywołanie własnej metody np. self.cell(x)\n","- w konstruktorze modelu usuń inicjalizację komórki LSTM i zastąp ją inicjalizacją warstw potrzebnych do stworzenia własnej komórki rekurencyjnej,\n","- stwórz metodę cell() wykonującą operacje warstwy rekurencyjnej,\n","- prosta warstwa rekurencyjna konkatenuje poprzedni wyniki i aktualny input, a następnie przepuszcza ten połączony tensor przez warstwę gęstą (Dense)."]},{"cell_type":"code","metadata":{"id":"BGQr50EafxSH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"f0503bc1-6086-43e5-a22c-d6dc214e400f","executionInfo":{"status":"ok","timestamp":1580657352514,"user_tz":-60,"elapsed":500931,"user":{"displayName":"Dominik Szmyt","photoUrl":"","userId":"04255669248458570913"}}},"source":["class CustomCellModel(Model):\n","\n","    def __init__(self, num_classes=10):\n","        super(CustomCellModel, self).__init__(name='custom_cell_model')\n","        self.num_classes = num_classes\n","\n","        self.dense_1 = Dense(128, activation='relu')\n","        self.dense_2 = Dense(self.num_classes, activation='softmax') \n","\n","    def call(self, inputs):\n","        sequence = tf.random.normal([32,128])\n","        for i in range(28):\n","            sequence = self.cell(inputs[:,i,:], sequence)\n","        return self.dense_2(sequence)\n","    \n","    def cell(self, inputs, sequence):\n","        out = K.concatenate([sequence, inputs], 1)\n","        return self.dense_1(out)\n","\n","customCellModel = CustomCellModel()\n","\n","customCellModel.compile(optimizer=RMSprop(),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","customCellModel.fit(x_train, y_train, batch_size=32, epochs=2)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Train on 60000 samples\n","Epoch 1/2\n","60000/60000 [==============================] - 15s 252us/sample - loss: 0.5512 - accuracy: 0.8207\n","Epoch 2/2\n","60000/60000 [==============================] - 14s 230us/sample - loss: 0.2203 - accuracy: 0.9376\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fcec97d2160>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"_3sOaUu3b77l","colab_type":"text"},"source":["### Zadanie 5\n","\n","Na podstawie modelu z poprzedniego zadania stwórz model z własną implementacją warstwy LSTM. Dokładny i zrozumiały opis działania warstwy LSTM znajduje się na [stronie](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)."]},{"cell_type":"code","metadata":{"id":"Kyu4YijDcA13","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"fe681645-4fb2-427e-f697-5d978c3411f1","executionInfo":{"status":"ok","timestamp":1580657421001,"user_tz":-60,"elapsed":569408,"user":{"displayName":"Dominik Szmyt","photoUrl":"","userId":"04255669248458570913"}}},"source":["class CustomLSTMModel(Model):\n","\n","    def __init__(self, num_classes=10):\n","        super(CustomLSTMModel, self).__init__(name='custom_lstm_model')\n","        self.num_classes = num_classes\n","\n","        self.dense_1 = Dense(128, activation='sigmoid')\n","        self.dense_2 = Dense(128, activation='sigmoid')\n","        self.dense_3 = Dense(128, activation='tanh')\n","        self.dense_4 = Dense(self.num_classes, activation='softmax') \n","\n","    def call(self, inputs):\n","        sequence = tf.random.normal([32,128])\n","        for i in range(28):\n","            sequence = self.cell(inputs[:,i,:], sequence)\n","        return self.dense_4(sequence)\n","    \n","    def cell(self, inputs, h_prev):\n","        x_1 = K.concatenate([h_prev, inputs], 1)\n","        z = self.dense_1(x_1)\n","        r = self.dense_2(x_1)\n","        x_2 = K.concatenate([r * h_prev, inputs], 1)\n","        h = self.dense_3(x_2)\n","        return (1 - z) * h_prev + z * h\n","\n","customLSTMModel = CustomLSTMModel()\n","\n","customLSTMModel.compile(optimizer=RMSprop(),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","customLSTMModel.fit(x_train, y_train, batch_size=32, epochs=2)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Train on 60000 samples\n","Epoch 1/2\n","60000/60000 [==============================] - 35s 589us/sample - loss: 0.3183 - accuracy: 0.8973\n","Epoch 2/2\n","60000/60000 [==============================] - 32s 541us/sample - loss: 0.0897 - accuracy: 0.9724\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fcec8b53668>"]},"metadata":{"tags":[]},"execution_count":10}]}]}